# 公众号内容拓展学习笔记（2022.3.16）

------



## :paperclip:  今日要点

1. [CVPR 2022｜MPViT：用于密集预测的多路径视觉Transformer](https://mp.weixin.qq.com/s/D0u1th6g1OhuSphGdXvVJg)         :star::star:
   - Abstract: MPViT：用于密集预测的多路径视觉Transformer
   - Paper: [MPViT: Multi-Path Vision Transformer for Dense Prediction](https://arxiv.org/abs/2112.11010)
   - Code: [https://github.com/youngwanLEE/MPViT](https://github.com/youngwanLEE/MPViT)
   - Tips:  作者们以与现有 Transformer 不同的视角，探索多尺度path embedding与multi-path结构结构，构建多路径视觉 Transformer (MPViT)。大量的实验也表明表明 MPViT 可以作为各种视觉任务的多功能骨干网络。

<div align=center><img src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/gYUsOT36vfoCmqzibQ9WAY8qTEcOeN7sToE8G8deX8tPL4zN9sHn6o5BxB3gVjeXsg6utjEhpBkFP0EI5fzVwIQ/640?wx_fmt=jpeg&wxfrom=5&wx_lazy=1&wx_co=1" style='zoom:100%'>
</div>

2. [即插即用 | S-FPN全新的金字塔网络，更适合轻量化模型的FPN](https://mp.weixin.qq.com/s/sDuBN3qVxlRth5vlOUoEjg)       :star::star:
   - Abstract: S-FPN全新的金字塔网络，更适合轻量化模型的FPN
   - Paper: [SFPN: Synthetic FPN for Object Detection](https://arxiv.org/abs/2203.02445)
   - Tips:  本文提出了一种新的金字塔网络，SFPN（合成融合金字塔网络），该结构在原始FPN层之间创建各种合成层，以提高轻量CNN Backbone的精度，更准确地提取目标的视觉特征。最后，实验证明了SFPN架构对于各种Backbone的有效性。 

<div align=center><img src="https://mmbiz.qpic.cn/mmbiz_png/5ooHoYt0tgmo0B76XacyYrTiayXLYNWBo2KAcPCFd9WJgZSjFFk5RvQKN8icbJImMRMgyEznTxPOxicVQeicgnSr3w/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" style='zoom:100%'>
</div>


3. [CVPR 2022｜群核前沿院等提出首个基于数据驱动的面检测算法](https://mp.weixin.qq.com/s/BGVp__Ku12yKtElkfaPm3w)       :star::star:
   - Abstract: 首个基于数据驱动的面检测算法
   - Paper: [Neural Face Identification in a 2D Wireframe Projection of a Manifold Object](https://arxiv.org/abs/2203.04229)
   - Code: [https://github.com/manycore-research/faceformer](https://github.com/manycore-research/faceformer)
   - Tips: 本文从数据驱动的角度重新审视从线框图中检测面这一经典问题，将其建模为序列生成问题：从任意一条开始，采用流行的基于Transformer的模型，以自然顺序预测属于同一个面的其他边。
<div align=center><img src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/gYUsOT36vfombIxb5PGBOufibaSlBlomgHibhicshicMlDiaIy5FjewTQqxCow2CfHiaN8szQdf3JReCRrF23N7vmecw/640?wx_fmt=jpeg&wxfrom=5&wx_lazy=1&wx_co=1" style='zoom:100%'>
</div>


4. [RepLKNet作者解读：超大卷积核，大到31x31，越大越暴力，涨点又高效！（CVPR 2022）](https://mp.weixin.qq.com/s/DSXBgB4Ry1Tvu6JsOiaCeQ)       :star::star:
   - Abstract: RepLKNet作者解读：超大卷积核，大到31x31，越大越暴力，涨点又高效！
   - Paper: [Scaling Up Your Kernels to 31x31: Revisiting Large Kernel Design in CNNs](https://arxiv.org/abs/2203.06717)
   - Code: [https://github.com/DingXiaoH/RepLKNet-pytorch](https://github.com/DingXiaoH/RepLKNet-pytorch)
   - Tips: CNN中的kernel size是一个非常重要但总是被人忽略的设计维度，在现代模型设计的加持下，卷积核越大越暴力，既涨点又高效，甚至大到31x31都非常work，即便在大体量下游任务上，我们提出的超大卷积核模型RepLKNet与Swin等Transformer相比，性能也更好或相当！

<div align=center><img src="https://mmbiz.qpic.cn/mmbiz_jpg/SjQAYGc0mKGqMnA9XpJMbXaD3g8pNZb4wTnfLich6NwPE6ic3tUsA8nhyfFkdBNr8yXKSu4bAAVD8qLRP0VJCQTQ/640?wx_fmt=jpeg&wxfrom=5&wx_lazy=1&wx_co=1" style='zoom:100%'>
</div>


5. [CVPR2022 做语义分割不用任何像素标签，UCSD、英伟达在ViT中加入分组模块](https://mp.weixin.qq.com/s/P1vHiMVS93vo_KRUi6GUKw)       :star::star:
   - Abstract: 做语义分割不用任何像素标签，UCSD、英伟达在ViT中加入分组模块
   - Paper: [GroupViT: Semantic Segmentation Emerges from Text Supervision](https://arxiv.org/pdf/2202.11094.pdf)
   - Tips: 该研究的关键思想是利用视觉 Transformer（ViT）在其中加入新的视觉分组模块，研究者将新模型称为 GroupViT（分组视觉 Transformer）。

<div align=center><img src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWib6UUVmR1ScTBB62bgBesic0umuK9dtyqgowkAVKr3zv2gIGQGqdPxxcJ4kjoCbUkjRVzzGVdicibd5Q/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" style='zoom:100%'>
</div>


6. [短袖短裤识别算法冠军方案总结 | 极市打榜](https://mp.weixin.qq.com/s/Z0-lMwTRLwM-HaqNT0gQtQ)       :star::star:
   - Abstract: 短袖短裤识别算法冠军方案总结
   - Tips: 本文为短裤短袖识别算法的冠军tourist，总结了他当时参珠港澳人工智能算法大赛和最近参与打榜的一些技术细节和经验

<div align=center><img src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/gYUsOT36vfombIxb5PGBOufibaSlBlomg4RfLX6Qrv3gtFbAgk0jNoAcSG1Tc5YSfztKAicpdAAXUhQIErqQzPiaQ/640?wx_fmt=jpeg&wxfrom=5&wx_lazy=1&wx_co=1" style='zoom:100%'>
</div>



## :paperclip:  Others

- 由于图片权限问题，[GitHub](https://github.com/xiaoxuebajie/dairly_learning)是完整版，可以点点 star
- 星标的数量是与个人相关程度，不代表文章内容的好坏
- 关注我的[个人网站](http://www.cvbds.cn/)
- 关注我的[CSDN](https://blog.csdn.net/xiaoxuebajie)博客
- 关注我的[哔哩哔哩](https://space.bilibili.com/424394389)
- 关注我的公众号CV伴读社

<div align=center><img src="https://img-blog.csdnimg.cn/202005031406335.jpg" style='zoom:80%'>
</div>