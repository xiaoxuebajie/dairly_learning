# 公众号内容拓展学习笔记（2022.3.11）

------



## :paperclip:  今日要点

1. [CVPR | Facebook提出FP-NAS：搜索速度更快、分类精度更高、性能更好](https://mp.weixin.qq.com/s/4v0grlvv7wARd_Dh5_uD_g)         :star::star:
   - Abstract: Facebook提出FP-NAS：搜索速度更快、分类精度更高、性能更好
   - Paper: [FP-NAS: Fast Probabilistic Neural Architecture Search](https://arxiv.org/abs/2011.10949)
   - Tips:  该算法采用自适应架构概率分布熵的架构采样，能够减少采样样本达 60%，加速搜索快 1.8 倍。此外，该算法还包括一种新的基于分解概率分布的由粗到细的搜索策略，进一步加速搜索快达 1.2 倍。

<div align=center><img src="https://mmbiz.qpic.cn/mmbiz_png/1MtnAxmWSwPxfJIiaWYwh2arlsxvdZLDtQYeiapticwXfSjUolTu56HXccKaPA4FArwVffqvoTEIn7WwcQXXptRrQ/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" style='zoom:100%'>
</div>

2. [CVPR最有趣论文 | 再模糊的照片AI都可以可以恢复](https://mp.weixin.qq.com/s/KmizgnGOfirFh08UFX_G7Q)       :star::star:
   - Abstract: 再模糊的照片AI都可以可以恢复
   - Paper: [Towards Real-World Blind Face Restoration with Generative Facial Prior](https://arxiv.org/pdf/2101.04061.pdf)
   - Code: [https://github.com/TencentARC/GFPGAN](https://github.com/TencentARC/GFPGAN)
   - Tips:  GFP-GAN框架的概述：它包括一个degradation removal模块和一个预先训练好的face GAN作为 facial prior。它们由latent code映射和几个Channel-Split Spatial Feature Transform(CSSFT)层。所提出的CS-SFT调制实现了良好的保真度和保真度平衡。

<div align=center><img src="https://mmbiz.qpic.cn/mmbiz_png/1MtnAxmWSwPxfJIiaWYwh2arlsxvdZLDtgGm8wGl9SwWy2ZWM4Flmyr0hUoo9uzp7sxagDT9j8slJwfkd4eAMyQ/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" style='zoom:100%'>
</div>




3. [ZippyPoint: 一种基于学习的特征点提取+二进制描述子，速度提升5倍+，为移动平台提供一种ORB的替代方案](https://mp.weixin.qq.com/s/1Kw3j6yT7koZdJ0HDUm93g)       :star::star:
   - Abstract: MIT最新研究：ZippyPoint: 一种基于学习的特征点提取+二进制描述子，速度提升5倍+，为移动平台提供一种ORB的替代方案
   - Paper: [ZippyPoint: Fast Interest Point Detection, Description, and Matching through Mixed Precision Discretization](https://arxiv.org/abs/2203.03610)
   - Tips: 本文设计了ZippyPoint，它是一个用于特征点提取的网络。与ORB的描述子类似，ZippyPoint得到的也是二进制描述子。该特征点可以获得与基于学习的特征匹配以及视觉定位性能，同时速度提升5倍。
<div align=center><img src="https://mmbiz.qpic.cn/mmbiz_png/RkDHyHvXvJ6yBlr3JfYhXF9GSagyDaWxIDrlA5QjG8fNkhhGZ2tmiasQ3iau6QutoEnUfhtIpiaOLd7ww76WAkmiaw/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" style='zoom:100%'>
</div>




4. [CVPR 2022 最新 65 篇论文分方向整理｜包含目标检测、动作识别、人群计数等方向（附打包下载）](https://mp.weixin.qq.com/s/TAMflTf8RBtHBknom9F6yw)       :star::star:
   - Abstract: CVPR 2022 最新 65 篇论文分方向整理｜包含目标检测、动作识别、人群计数等方向
   - Address: [https://bbs.cvmart.net/articles/6124](https://bbs.cvmart.net/articles/6124)
   - Tips: 65 篇 CVPR 2022 论文，包含目标检测、异常检测、超分辨率、姿态估计、三维重建、医学影像、动作识别、人群计数、视觉预测、图像特征匹配等方向。

<div align=center><img src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/gYUsOT36vfo3T7brEa3n6ropDWL85EHYQFBicwQpdUH7LExY7qUSv6qE40thCehaSfoHNrxicclk3vRdj6d42mHg/640?wx_fmt=jpeg&wxfrom=5&wx_lazy=1&wx_co=1" style='zoom:100%'>
</div>


5. [YOLOv5-Lite 详解教程 | 嚼碎所有原理、训练自己数据集、TensorRT部署落地应有尽有](https://mp.weixin.qq.com/s/CuLuoaGaN8AaXj67Y1Y21A)       :star::star:
   - Abstract: YOLOv5-Lite 详解教程
   - Tips: YOLOv5 Lite在YOLOv5的基础上进行一系列消融实验，使其更轻（Flops更小，内存占用更低，参数更少），更快（加入shuffle channel，yolov5 head进行通道裁剪，在320的input_size至少能在树莓派4B上的推理速度可以达到10+FPS），更易部署（摘除Focus层和4次slice操作，让模型量化精度下降在可接受范围内）。

<div align=center><img src="https://mmbiz.qpic.cn/mmbiz_jpg/5ooHoYt0tgnkY0YNkpaibu2ZxNOjEdtOMA75WP85XzHicdFzCSJcibMmfLIia6yaTBcF7Ux5VH4zThrlO2YGDFQjRw/640?wx_fmt=jpeg&wxfrom=5&wx_lazy=1&wx_co=1" style='zoom:100%'>
</div>




6. [模型量化技巧及在低功耗IOT设备的应用实践](https://mp.weixin.qq.com/s/KWyM3mgvZhtlcuXaodNJ3A)       :star::star:
   - Abstract: 模型量化技巧及在低功耗IOT设备的应用实践
   - Tips: 本文介绍了神经网络模型在轻量级设备的部署技巧，具体内容包括神经网络模型量化的基本原理和主要方法，以及部分低功耗IOT设备上模型部署的实例与技巧。

<div align=center><img src="https://mmbiz.qpic.cn/mmbiz_png/xm3mwmQ97RcWfJt9Zonu6uzOY7RzOUkoAbS0M73icWY6sATPMbenPxib9IJTQebFYpiaXOA2ElqytjFDPmwVm9Zdw/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" style='zoom:100%'>
</div>





## :paperclip:  Others

- 由于图片权限问题，[GitHub](https://github.com/xiaoxuebajie/dairly_learning)是完整版，可以点点 star
- 星标的数量是与个人相关程度，不代表文章内容的好坏
- 关注我的[个人网站](http://www.cvbds.cn/)
- 关注我的[CSDN](https://blog.csdn.net/xiaoxuebajie)博客
- 关注我的[哔哩哔哩](https://space.bilibili.com/424394389)
- 关注我的公众号CV伴读社

<div align=center><img src="https://img-blog.csdnimg.cn/202005031406335.jpg" style='zoom:80%'>
</div>