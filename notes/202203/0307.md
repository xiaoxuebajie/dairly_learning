# 公众号内容拓展学习笔记（2022.3.7）

------



## :paperclip:  今日要点

1. [MUCNetV2：内存瓶颈和计算负载问题一举突破？分类&检测都有较高性能（附源代码下载）](https://mp.weixin.qq.com/s/0ORxzgOBK2EaICydw2WC2g)         :star::star:
   - Abstract: MUCNetV2：内存瓶颈和计算负载问题一举突破？分类&检测都有较高性能（附源代码下载）
   - Paper: [MCUNetV2: Memory-Efficient Patch-based Inference for Tiny Deep Learning](https://arxiv.org/pdf/2110.15352.pdf)
   - Code: [https://mcunet.mit.edu](https://mcunet.mit.edu)
   - Tips:  研究者提出一种patch-based inference机制打破初始层的内存瓶颈问题,极大程度上解决了TinyDL的内存瓶颈问题，为图像分类之外的其他视觉应用铺平了道路 。

<div align=center><img src="https://mmbiz.qpic.cn/mmbiz_png/1MtnAxmWSwMrPYfnqvA52o0lj84mRMSmv6Ez4E4xFyybdvibggYra3tYWrhLDaJIPPTw2LXPqqASkoWIMSnpDhA/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" style='zoom:100%'>
</div>

2. [一举打败16个同类模型，视频超分比赛冠军算法入选CVPR 2022，来自商汤&南洋理工大学](https://mp.weixin.qq.com/s/dowmz_mI7ZxNSCFjmKwibg)       :star::star:
   - Abstract: 来自商汤&南洋理工大学视频超分比赛冠军算法BasicVSR++
   - Paper: [BasicVSR++: Improving Video Super-Resolution with Enhanced Propagation and Alignment](https://arxiv.org/abs/2104.13371)
   - Code: [https://github.com/ckkelvinchan/RealBasicVSR](https://github.com/ckkelvinchan/RealBasicVSR)
   - Tips: 加强版的BasicVSR++在传播和对齐方面进行了重新改造，采用了二阶网格传播(second-order grid propagation) 和光流引导可变形对齐 (flow-guided deformable alignment)的设计来改善网络中的信息聚合能力，提升遮挡区域的鲁棒性和有效性。

<div align=center><img src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCC7Xkc0OYK2GKZgNjRf6IiaIDhN1kvg40G3eSzxYJ0teVAlLxgft6NCibbzFYEBZMcKzVC301wpicdg/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" style='zoom:100%'>
</div>


3. [CVPR 2022 | 即插即用！助力自监督涨点的ContrastiveCrop开源了！](https://mp.weixin.qq.com/s/VTP9D5f7KG9vg30U9kVI2A)       :star::star:
   - Abstract: 即插即用！助力自监督涨点的ContrastiveCrop开源了！
   - Paper: [Crafting Better Contrastive Views for Siamese Representation Learning](https://arxiv.org/abs/2202.03278)
   - Code: [https://github.com/xyupeng/ContrastiveCrop](https://github.com/xyupeng/ContrastiveCrop)
   - Tips: ContrastiveCrop旨在确保大部分正样本对语义一致的前提下，加大样本之间的差异性，从而通过最小化对比损失学习到更泛化的特征。ContrastiveCrop完全即插即用，且理论上适用于任何孪生网络架构。
<div align=center><img src="https://mmbiz.qpic.cn/mmbiz_png/yNnalkXE7oXhCL15yhpoXRnPzYOnIgVqM7HAtmBETewLAHvFt0ktwSxDhlR4Yy5q4LhbdjNOSM0Y1qLDT49fFw/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" style='zoom:100%'>
</div>


4. [女娲算法，杀疯了！](https://mp.weixin.qq.com/s/v_hB5BGuzRTBqQfrHb4OlA)       :star::star:
   - Abstract: 多模态算法NÜWA（女娲）
   - Paper: [NÜWA: Visual Synthesis Pre-training for Neural visUal World creAtion](https://arxiv.org/abs/2111.12417)
   - Code: [https://github.com/microsoft/NUWA](https://github.com/microsoft/NUWA)
   - Tips: NÜWA模型的整体架构包含一个支持多种条件的 adaptive 编码器和一个预训练的解码器，能够同时使图像和视频的信息。对于图像补全、视频预测、图像处理和视频处理任务，将输入的部分图像或视频直接送入解码器即可。

<div align=center><img src="https://mmbiz.qpic.cn/mmbiz_png/v1JN0W4OpXjKxdrh3FDZeCbe2ZnbF12X9hhAPVWLgJbxfDsQYibLiaeX0IQeWeAicR34iac4bib8JWlf5Q8Gqo9EichQ/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" style='zoom:100%'>
</div>


5. [ICRA 2022 | 基于多模态变分自编码器的任意时刻三维物体重建](https://mp.weixin.qq.com/s/5U4GN76q7uR-mHN79fKFkw)       :star::star:
   - Abstract: 基于多模态变分自编码器的任意时刻三维物体重建
   - Paper: [Anytime3D Object Reconstruction Using Multi-Modal Variational Autoencoder](https://arxiv.org/abs/2101.10391)
   - Tips: 为了实现类别级的插补和完整的三维形状重建，研究人员利用了潜在空间的多模态先验分布思想。与普通VAE不同，该方法中的每个模态都是在训练时自动确定的，并且包含特定类别的信息。利用这种先验分布，研究人员仅利用潜在空间中的传输元素来确定潜在变量的模式。通过从所选模型中输入采样变量，研究人员可以稳健地实现潜在向量检索和三维形状重建。

<div align=center><img src="https://mmbiz.qpic.cn/mmbiz_png/Q0FNTB1XHiczXF0P0oEzB6XCMib6yz4MOiaDTICm6icOxhj17uTIUp4dfpoCObIR6TaK0qmT3XL2KcZ2vNeswTaB1A/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" style='zoom:100%'>
</div>


6. [基于大尺寸图像的小目标检测竞赛经验总结](https://mp.weixin.qq.com/s/qbbd5FdyKKk7UI3mmGBt4Q)       :star::star:
   - Abstract: 基于大尺寸图像的小目标检测竞赛经验总结
   - Tips: 本文为作者参加目标检测比赛总结的数据分析，比赛思路、模型、Tricks以及分享的一些相关资料。附有详细的模型总结以及anchor的设置总结图。

<div align=center><img src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/gYUsOT36vfrqgczsQvHuFU02XwN3KL28ichBLll8Ku0bfC59fFlDBmFbPSBv488kaEWicBLDLeHbd4UJOu0ZshPw/640?wx_fmt=jpeg&wxfrom=5&wx_lazy=1&wx_co=1" style='zoom:100%'>
</div>



## :paperclip:  Others

- 由于图片权限问题，[GitHub](https://github.com/xiaoxuebajie/dairly_learning)是完整版，可以点点 star
- 星标的数量是与个人相关程度，不代表文章内容的好坏
- 关注我的[个人网站](http://www.cvbds.cn/)
- 关注我的[CSDN](https://blog.csdn.net/xiaoxuebajie)博客
- 关注我的[哔哩哔哩](https://space.bilibili.com/424394389)
- 关注我的公众号CV伴读社

<div align=center><img src="https://img-blog.csdnimg.cn/202005031406335.jpg" style='zoom:80%'>
</div>