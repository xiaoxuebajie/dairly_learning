# 公众号内容拓展学习笔记（2022.3.30）

------



## :paperclip:  今日要点

1. [CVPR 2022｜基于GAN逆映射的高保真图像编辑算法 by 港科大&腾讯AI Lab开源](https://mp.weixin.qq.com/s/AYQWrbdIynwglxFUz_Ri5Q)         :star::star:
   - Abstract: 基于GAN逆映射的高保真图像编辑算法
   - Paper: [High-Fidelity GAN Inversion for Image Attribute Editing](https://arxiv.org/abs/2109.06590)
   - Code: [https://github.com/Tengfei-Wang/HFGI](https://github.com/Tengfei-Wang/HFGI)
   - Tips:  本文提出了一种名为信息参照（information consultation）的方法，同时利用low-rate和high-rate隐编码。该模型包括两个编码器，基础编码器压缩低率隐编码，用于保证图像的可编辑性；参照编码器对低率重建图像的失真信息进行补充编码，得到一个高率的隐编码，补充丢失的细节信息。

<div align=center><img src="https://mmbiz.qpic.cn/sz_mmbiz_png/gYUsOT36vfo2EXh31yIPtb0f44V0uEcUq88NU7TwRHa7rCrMK99bVC0SkDasTicWoHJgvCKJvZCLo7X8IuOdOcA/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" style='zoom:100%'>
</div>

2. [CVPR 2022 | 华南理工提出VISTA：双跨视角空间注意力机制实现3D目标检测SOTA，即插即用](https://mp.weixin.qq.com/s/QJmqRk0tqZd-4Io1TBM-9g)       :star::star:
   - Abstract: 华南理工提出VISTA：双跨视角空间注意力机制实现3D目标检测SOTA，即插即用
   - Paper: [VISTA: Boosting 3D Object Detection via Dual Cross-VIew SpaTial Attention](https://arxiv.org/abs/2203.09704)
   - Code: [https://github.com/Gorilla-Lab-SCUT/VISTA](https://github.com/Gorilla-Lab-SCUT/VISTA)
   - Tips:  本文提出了 VISTA，一种新颖的即插即用多视角融合策略，用于准确的 3D 对象检测。为了使 VISTA 能够关注特定目标而不是一般点，研究者提出限制学习的注意力权重的方差。将分类和回归任务解耦以处理不平衡训练问题。

<div align=center><img src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8ibFhOLCfAmFN6s8icGW9WYkibMvSwHicF5Wcwp7k2OOmE7Z1JnoNkHChPfmu4gsH7ribe6rF6y4hatcw/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" style='zoom:100%'>
</div>


3. [CVPR 2022｜Adobe提出InsetGAN！ 全身都生成，这可太GAN了](https://mp.weixin.qq.com/s/4sR6IDlhYKAu8T4g05hzcg)       :star::star:
   - Abstract: Adobe提出InsetGAN！ 全身都生成，这可太GAN了
   - Paper: [InsetGAN for Full-Body Image Generation](https://arxiv.org/abs/2203.07293)
   - Tips: 他们首先引入了一个边界框检测器，检测部分GAN生成的特定区域在底层画布，也就是全身GAN生成的区域中的位置，经过裁剪后再将特定区域嵌入。
<div align=center><img src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/gYUsOT36vfo1C6AbudEABOxOdvicXC5icGM3FoT7uUfMHZxqqOvia2UxFDibAAeiaJl9y0aOaSnSKQdodWY9ZUglncw/640?wx_fmt=jpeg&wxfrom=5&wx_lazy=1&wx_co=1" style='zoom:100%'>
</div>


4. [Swim-Transform V2：用于目标检测，视觉大模型不再是难题（附源代码）](https://mp.weixin.qq.com/s/8ItDlfkQfTrdpJc9A2luuQ)       :star::star:
   - Abstract: Swim-Transform V2：用于目标检测，视觉大模型不再是难题（附源代码）
   - Paper: [Swin Transformer V2: Scaling Up Capacity and Resolution](https://arxiv.org/pdf/2111.09883.pdf)
   - Code: [https://github.com/microsoft/Swin-Transformer](https://github.com/microsoft/Swin-Transformer)
   - Tips: MSRA时隔大半年放出了Swin Transformer 2.0版本，在1.0版本的基础上做了改动，使得模型规模更大并且能适配不同分辨率的图片和不同尺寸的窗口！这也证实了，Transformer将是视觉领域的研究趋势！

<div align=center><img src="https://mmbiz.qpic.cn/mmbiz_png/1MtnAxmWSwPafgZwmXyn9YJVUPgaIroNicficOibzZmqTToVC7Zm7vKmY8DbicVENCl2Au3pHX7oDBKWG2usc8s22A/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" style='zoom:100%'>
</div>


5. [CVPR 2022 | 天大本科生论文入选！深度学习长尾分类新SOTA](https://mp.weixin.qq.com/s/n7jloECjzmhftMeZBwfWdA)       :star::star:
   - Abstract: 深度学习长尾分类新SOTA
   - Paper: [Trustworthy Long-Tailed Classification](https://arxiv.org/abs/2111.09030)
   - Tips: 通过引入不确定性集成，来实现对尾部类别样本的自动感知。在此基础上，提出为尾部类别样本动态分配比头部样本更多的模型资源（experts），以兼顾性能与效率。

<div align=center><img src="https://mmbiz.qpic.cn/mmbiz_png/5fknb41ib9qFQcBXEhW2NFnD8ZibVJAavpxoviaqUyicibEth2icXXicAGar7fLGbPyPzokOEIh1Ob0z9dKLWKHOHoNaw/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" style='zoom:100%'>
</div>


6. [刷新4个SOTA！港大&字节开源ReferFormer: 语言作为查询的视频目标分割框架](https://mp.weixin.qq.com/s/MsEBgLRJ8TxTS6opeewNyw)       :star::star:
   - Abstract: 港大&字节开源ReferFormer: 语言作为查询的视频目标分割框架
   - Paper: [Language as Queries for Referring Video Object Segmentation](https://arxiv.org/abs/2201.00487)
   - Code: [https://github.com/wjn922/ReferFormer](https://github.com/wjn922/ReferFormer)
   - Tips: 研究者们提出了一种基于Transformer的参考视频目标分割新框架ReferFormer。其将语言描述视为查询条件，直接在视频中查找目标对象，除此之外，通过实例序列的整体输出自然地完成目标物体的跟踪，无需进行任何后处理。

<div align=center><img src="https://mmbiz.qpic.cn/mmbiz_png/yNnalkXE7oUEGwNWCu09LOic1W2uZbblYpsndsxhTMucEG9E6VcYmPJoYAq9I5MibOnQxbTKOnpGPgkUvUhSSXyg/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" style='zoom:100%'>
</div>



## :paperclip:  Others

- 由于图片权限问题，[GitHub](https://github.com/xiaoxuebajie/dairly_learning)是完整版，可以点点 star
- 星标的数量是与个人相关程度，不代表文章内容的好坏
- 关注我的[个人网站](http://www.cvbds.cn/)
- 关注我的[CSDN](https://blog.csdn.net/xiaoxuebajie)博客
- 关注我的[哔哩哔哩](https://space.bilibili.com/424394389)
- 关注我的公众号CV伴读社

<div align=center><img src="https://img-blog.csdnimg.cn/202005031406335.jpg" style='zoom:80%'>
</div>