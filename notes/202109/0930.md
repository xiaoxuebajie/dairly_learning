# 公众号内容拓展学习笔记（2021.9.30）

------



## :paperclip:  今日要点

1. [ICCV 2021 | ResRep：剪枝SOTA！用结构重参数化实现CNN无损压缩](https://mp.weixin.qq.com/s/88nRC3VttYBsuTZ5S49Iww)         :star::star:
   - Abstract: ResRep用结构重参数化实现CNN无损压缩
   - Paper: [ResRep: Lossless CNN Pruning via Decoupling Remembering and Forgetting](https://arxiv.org/abs/2007.03260)
   - Code: [https://github.com/DingXiaoH/ResRep](https://github.com/DingXiaoH/ResRep)
   - Tips:  将原CNN等价拆分成负责“记忆”（保持精度不降低）的部分和负责“遗忘”（去掉某些通道）的部分，前者进行“记忆训练”，后者进行“遗忘训练”。

<div align=center><img src="https://mmbiz.qpic.cn/mmbiz_png/ibaXaPIy7jV3lC5xFY2lIsWycerFiaXgEdt1HNr87KHnIUNMVzK6hVjTYCsIFUxkn6fFPsLKxarwxkziaP4trQ8Jw/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" style='zoom:100%'>
</div>

2. [深入探究ConvNets vs. Transformers，哪种预训练模型的可迁移性更好？](https://mp.weixin.qq.com/s/lH4o_g319N4Xeq2hi5UQvg)       :star::star:
   - Abstract: 通过下游实验来验证ConvNets和Transformers哪个预训练模型的可迁移性更好
   - Paper: [ConvNets vs. Transformers: Whose Visual Representations are More Transferable?](https://arxiv.org/abs/2108.05305)
   - Tips: 综合表现Transformers更佳，传统的观点一般认为Transformer优于ConvNets的原因是在于其更加放松（relaxed）的inductive bias。通过系统的实验，我们认为使得Transformer的迁移性能优于ConvNets的另外一大原因是其在提供相近ImageNet预训练性能的情况下，具有更少的参数量，这有利于降低预训练模型在下游任务上过拟合的风险。

<div align=center><img src="https://mmbiz.qpic.cn/mmbiz_png/BJbRvwibeSTue6LO8k8PoDcHCVkJibPFGnZN4bElk1KraUhax91cXH19Y6jtQoibmnOagL6WibKWrjecPSXCVhsInw/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" style='zoom:100%'>
</div>


3. [CVPR 2021 比CNN和Transformer更好的Backbone？伯克利&谷歌提出BoTNet，精度达84.7%](https://mp.weixin.qq.com/s/A40zE1CA_YwovI53eLGA1A)       :star::star:
   - Abstract: BoTNet比CNN和Transformer更好的Backbone
   - Paper: [Bottleneck Transformers for Visual Recognition](https://arxiv.org/abs/2101.11605)
   - Tips: 直接将ResNet C5中的3x3卷积替换成了Self-Attention，来提升模型的性能
<div align=center><img src="https://mmbiz.qpic.cn/mmbiz_png/BJbRvwibeSTt3F9VlTib8RB3o9sZhnxSECnbZEMZyOEmJfHZpclc0Iy3Rmu0ibmKst9vmQR6HcdGqzsXp5teevU2A/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" style='zoom:100%'>
</div>

4. [语义分割综述](https://mp.weixin.qq.com/s/Tz7kT14S8ZkWZ-OgE2WO5g)       :star::star:
   - Abstract:  有关语义分割的文献综述
   - Tips: 比较经典的几篇文章，适合研究语义分割的同学好好看看。

<div align=center><img src="https://mmbiz.qpic.cn/mmbiz_png/V2E1ll6kaTXGLrzSIq30EEb7tENQWaHn5l1pXWP1TYR8h1dZia1XWvPTKTKFaJexeT45L1cEG4KQR4LliapHdWyQ/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" style='zoom:100%'>
</div>

5. [高通人工智能应用创新大赛冠军方案解读](https://mp.weixin.qq.com/s/2efke2PymcqMstkw4httUA)       :star::star:
   - Abstract:高通人工智能应用创新大赛冠军方案解读
   - Tips: 解决方案更贴近工业应用，包括落地

<div align=center><img src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/gYUsOT36vfqkuEUVb8WJCRXZCY6HA6tu9eLm69ztjTstynjKFKWUqyPClaBxGic4aKoHFMZlw2AcPpLpsSrAm0A/640?wx_fmt=jpeg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" style='zoom:100%'>
</div>

6. [AI全自动钓鱼，原神游戏沦陷！（硬核开源）](https://mp.weixin.qq.com/s/zA1jnCS6o1UNPum_FoUQlg)       :star::star:
   - Abstract:AI全自动钓鱼项目详解
   - Code: [https://github.com/7eu7d7/genshin_auto_fish](https://github.com/7eu7d7/genshin_auto_fish)
   - bilibili: [https://www.bilibili.com/read/cv13270965](https://www.bilibili.com/read/cv13270965)
   - Tips: YOLOX 用于鱼的定位和类型的识别以及鱼竿落点的定位,DQN 用于自适应控制钓鱼过程的点击，让力度落在最佳区域内

<div align=center><img src="https://mmbiz.qpic.cn/mmbiz_gif/v1JN0W4OpXgShLltx9u3vsPxNRmvp29suzF38JQB1FbJccV4RQCT4C8dOgu6zWynAHITI18mTT55hVclZgVccg/640?wx_fmt=gif&tp=webp&wxfrom=5&wx_lazy=1" style='zoom:100%'>
</div>


## :paperclip:  Others

- 由于图片权限问题，[GitHub](https://github.com/xiaoxuebajie/dairly_learning)是完整版，可以点点 star
- 星标的数量是与个人相关程度，不代表文章内容的好坏
- 关注我的[个人网站](http://www.cvbds.cn/)
- 关注我的[CSDN](https://blog.csdn.net/xiaoxuebajie)博客
- 关注我的[哔哩哔哩](https://space.bilibili.com/424394389)
- 关注我的公众号CV伴读社

<div align=center><img src="https://img-blog.csdnimg.cn/202005031406335.jpg" style='zoom:80%'>
</div>