# 公众号内容拓展学习笔记（2021.3.27）

------



## :paperclip:  今日要点

1. [手把手写Demo系列之车道线检测](https://mp.weixin.qq.com/s/9lJAUtQuGpAyqrIxbjiqzw)         :star:
   - 主要内容：本文是一篇从零开始做车道线检测Demo的教学式文章，从场景的定义到模型微调的输出，描述车道线Demo式例程中在每个环节需要做的工作，以及中途可能会遇到的各种问题。
2. [用20篇论文走完知识蒸馏在 2014-2020 年的技术进展](https://mp.weixin.qq.com/s/lTIUUn8mzc0Pp5mhwYsFTw)        :star::star:
   - 主要内容：有关知识蒸馏技术发展的综述
   - 核心要点：三种主流方法：模型压缩算法，模型优化加速，优化工具与库
3. [本周AI开源项目精选 | 基于pytroch的ORC算法库及python高性能CPU分析](https://mp.weixin.qq.com/s/22xv2SvLfdcSFefMnTRtzQ)       :star::star:
   - 主要内容：**pytorchOCR** **基于pytorch的ocr算法库**，还有一些其他的，不感兴趣。
   - GitHub：[https://github.com/BADBADBADBOY/pytorchOCR](https://github.com/BADBADBADBOY/pytorchOCR)
4. [CV岗位面试题：简单说下YOLOv1,v2,v3,v4各自的特点与发展史](https://mp.weixin.qq.com/s/elcs3FpbnE1Q8hV2n91BPw)       :star::star:
   - 主要内容：YOLOv1,v2,v3,v4各自的特点与发展史，知识梳理。


5. [CVPR2021|ACNet再进化，清华大学&旷视科技提出Inception类型的DBB](https://mp.weixin.qq.com/s/JRFwfm6N3tcB0cU1u1-VhQ)       :star::star:
   - 主要内容：本文介绍了清华大学&旷视科技的丁霄汉博士在“过参数化”卷积方面继ACNet、RepVGG之后的又一次探索，它创造性的将Inception的多分支、多尺度思想与过参数化思想进行了一次组合，得到了本文所提出的DBB。
   - 论文：[Diverse Branch Block: Building a Convolution as an Inception-like Unit](https://arxiv.org/pdf/2103.13425.pdf)
   - GitHub：[https://github.com/DingXiaoH/DiverseBranchBlock](https://github.com/DingXiaoH/DiverseBranchBlock)
   - 核心要点：
     - 提出一种包含丰富信息的“微结构”且可以作为”即插即用“模块直接嵌入到现有ConvNet(保持模型的”宏观结构“不变)中提升模型性能；
     - 提出了一种通用模块组件DBB，它将六种矩阵变换等价转为单个卷积，做到了“推理耗时无损”；
     - 提出了一种特征表达方式类似Inception的DBB模块，它可以直接嵌入到ConvNet并取得了显著的性能提升，比如在ImageNet上取得了1.9%的top-1精度提升。
<div align=center><img src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/gYUsOT36vfr5CPcrkR86MibgNVFjd2HoBvANRDBUYfl95ICm5z7vPTicwWVbJOQ2AdQgXiau48L1ZmpU2U5gTUIQA/640?wx_fmt=jpeg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" style='zoom:50%'>
</div>

6. [综述：基于图的异常检测](https://mp.weixin.qq.com/s/2tEUT8GDx8apK3GhP_TDzw)       :star::star:
   - 主要内容：本文主要介绍了2018年三篇针对图的异常检测的顶会论文，这几篇文章工作创新性强、可解释性足，且很有启发性。 
7. [超越Transformer！AAAI 2021最佳论文：高效长序列预测模型](https://mp.weixin.qq.com/s/WtIjTlo2aWNBrEciiI1Faw)       :star::star:
   - 主要内容：Informer 的主要工作是使用 Transfomer 实现长序列预测（Long Sequence Time-Series Forecasting），以下称为 LSTF。针对 Transfomer 在长序列预测中的不足（平方时间复杂度、高内存占用和现有编解码结构的局限性），提出 ProbSparse 注意力机制、自注意力蒸馏技术和生成式解码器等模块解决或缓解上述问题
   - 论文：[Informer: Beyond Efficient Transformer for Long Sequence Time-Series Forecasting](https://arxiv.org/abs/2012.07436)
   - GitHub：[https://github.com/zhouhaoyi/ETDataset](https://github.com/zhouhaoyi/ETDataset)
   - 核心要点：
     - ProbSparse self-attention，笔者称其为概率稀疏自注意力，通过“筛选”Query 中的重要部分，减少相似度计算；
     - Self-attention distilling，笔者称其为自注意力蒸馏，通过卷积和最大池化减少维度和网络参数量；
     - Generative style decoder，笔者称为生成式解码器，一次前向计算输出所有预测结果。

<div align=center><img src="https://mmbiz.qpic.cn/mmbiz_png/3Ww0VVPUs8jiaBgAkC0aqtd5l5ozHtJiaJKAibq94D7xmuwm4oL4eyqWojvsF9R9iagMg8HylK5xicGrLmUuRAibqViag/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" style='zoom:50%'>
</div>

8. [刷爆HACS挑战赛时序动作检测榜单！TCANet：最强时序动作提名修正网络 CVPR 2021](https://mp.weixin.qq.com/s/8U_99TArEfCMynbdCVtiWg)       :star::star:
   - 主要内容：本文介绍了商汤科技城市计算研发组发表在CVPR2021上的工作，提出了一种基于时序上下文聚合的动作提名修正网络（TCANet）。
   - 论文：[Temporal Context Aggregation Network for Temporal Action Proposal Refinement](https://arxiv.org/abs/2103.13141.pdf)
9. [RankDataset：超大规模数据集加载利器](https://mp.weixin.qq.com/s/MNn0S6hQ3HE-RBY50mkwXQ)       :star:
   - 主要内容：文章介绍了RankDataset的代码训练过程，RankDataset从原理入手，在分布式的基础上，直接计算每个epoch当前rank需要训练的数据的index。优点是大量的节省内存，且不需要额外开server。
10. [ORB-SLAM3中的ORB提取](https://mp.weixin.qq.com/s/oYMLdNXaOrGAEKF5AEof8w)        :star:
    - 主要内容：本文介绍ORB相关的一些概念，FAST特征点、BRIEF描述子、ORB如何改进得到旋转不变性，然后从工程实践上介绍金字塔图像每层特征分配数量如何计算、四叉树如何精简特征点。如果有理解上的错误，请您指正。
11. [图像篡改检测 | D-Unet：用于图像篡改检测和定位的双编码器U-Net](https://mp.weixin.qq.com/s/zF0XIQREtti4oe61zLIXBQ)       :star:
    - 主要内容：性能优于FusionNet、C2RNet和RRU-Net等网络。
    - 论文：[D-Unet: A Dual-encoder U-Net for Image Splicing Forgery Detection and Localization](https://arxiv.org/abs/2012.01821)

<div align=center><img src="https://mmbiz.qpic.cn/mmbiz_png/SjQAYGc0mKG39ff1xP0lBU1rxIqr4Zuiaqzr0LAHcmJpzg4nHCFUfjqG4j7GuRNOqOxBkEER3m4rKB7FrqeuXKg/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" style='zoom:50%'>
</div>

12. [基于密度图的航空物体检测：理论与代码实现](https://mp.weixin.qq.com/s/eKCe70xNxVWjArh7jrub2g)       :star::star:
    - 主要内容：本文来谈一下基于深度学习的航空物体场景下的物体检测。航空物体这类场景一般由无人机空拍来收集数据，然后进行后处理来满足特定的任务场景，有些情况下要求实现实时反馈，甚至多任务。
13. [基于深度学习的低光照图像增强方法总结（2017-2019）](https://mp.weixin.qq.com/s/aYso5YxSa1wpNm-BAf6spA)        :star::star:
    - 主要内容：基于深度学习的低光照图像增强方法总结
14. [【源头活水】类似于Multi-head注意力的Multi-Cast Attention网络](https://mp.weixin.qq.com/s/uMyJBxE68UFVnX0N0N9WUg)       :star::star:
    - 主要内容：类似于Multi-head注意力的Multi-Cast Attention网络
    - 论文：[Multi-Cast Attention Networks for Retrieval-based Question Answering and Response Prediction](https://arxiv.org/pdf/1806.00778.pdf)
    - GitHub：[https://github.com/DengBoCong/nlp-paper](https://github.com/DengBoCong/nlp-paper)
    - 核心要点：
      - 消除调用任意k次注意力机制所需架构工程的需要，且不会产生任何后果。
      - 通过多次注意力调用建模多个视图以提高性能，即多播注意力(Multi-Cast Attention)。

<div align=center><img src="https://mmbiz.qpic.cn/mmbiz_jpg/AIR6eRePgjMOibE8Pnxwic5RMs3CzWoBjOxreAicKwtUA0kAqNr5Bick8bEXsdYQUKrlhXWEPZfDCicRYBGag9ianNQQ/640?wx_fmt=jpeg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" style='zoom:50%'>
</div>

## :paperclip:  Others

- 由于图片权限问题，[GitHub](https://github.com/xiaoxuebajie/dairly_learning)是完整版，可以点点 star
- 星标的数量是与个人相关程度，不代表文章内容的好坏
- 关注我的[CSDN](https://mp.csdn.net/console/article)博客
- 关注我的[哔哩哔哩](https://space.bilibili.com/424394389?spm_id_from=333.788.b_765f7570696e666f.1)
- 关注我的公众号CV伴读社

<div align=center><img src="https://img-blog.csdnimg.cn/202005031406335.jpg" style='zoom:80%'>
</div>