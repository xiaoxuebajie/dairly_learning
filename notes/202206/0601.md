# 公众号内容拓展学习笔记（2022.6.1）

------



## :paperclip:  今日要点

1. [性能超MAE、BEiT和MoCoV3！商汤&港中文提出MixMIM：在混合图像上进行MIM](https://mp.weixin.qq.com/s/moxZK6DeuUOGT3X0fFz2Rg)         :star::star:
   - Abstract: 性能超MAE、BEiT和MoCoV3！商汤&港中文提出MixMIM：在混合图像上进行MIM
   - Paper: [MixMIM: Mixed and Masked Image Modeling for Efficient Visual Representation Learning](https://arxiv.org/abs/2205.13137)
   - Code: [https://github.com/Sense-X/MixMIM](https://github.com/Sense-X/MixMIM)
   - Tips:  本文提出了一种混合掩蔽图像建模（MixMIM），用于有效的视觉表征学习。本文的MixMIM使用随机掩蔽混合两幅图像创建的混合输入，并应用双重重建从混合输入中恢复原始两幅图像。作者进一步探索了一种更简单但更强大的层次Transformer，以实现高效学习。

<div align=center><img src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/gYUsOT36vfrTgR62ylQsoKjM0jq7H5Cickdib3cQ550ltJbRlCW5Jl1iaIk1OC7SlvA43tqJbVmOv7sSglNp7vib8A/640?wx_fmt=jpeg&wxfrom=5&wx_lazy=1&wx_co=1" style='zoom:100%'>
</div>

2. [CVPR 2022 | Group R-CNN：化框为点，简化物体检测数据标注](https://mp.weixin.qq.com/s/2QFy-m3s8pekub_5XPYJYw)       :star::star:
   - Abstract: Group R-CNN：化框为点，简化物体检测数据标注
   - Paper: [Group R-CNN for Weakly Semi-supervised Object Detection with Points](https://arxiv.org/abs/2205.05920)
   - Code: [https://github.com/jshilong/GroupRCNN](https://github.com/jshilong/GroupRCNN)
   - Tips: 本文提出了 Group R-CNN，可以有效地使用点标注来提升检测器性能，大幅度超越之前的方法

<div align=center><img src="https://mmbiz.qpic.cn/mmbiz_png/ialW0xobVWP6AZuOsrEibGXYa2DCjibOADP7TPicKXVd5u7l326S2qN9lgoAWa0ibX3SPBM83V6qzezEpNbI0NfPY8A/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" style='zoom:100%'>
</div>


3. [南理工&上海AI Lab提出Uniform Masking，为基于金字塔结构的视觉Transformer进行MAE预训练！](https://mp.weixin.qq.com/s/TNxk1Z_9NFId01EJL7pSlA)       :star::star:
   - Abstract: 南理工&上海AI Lab提出Uniform Masking，为基于金字塔结构的视觉Transformer进行MAE预训练！
   - Paper: [Uniform Masking: Enabling MAE Pre-training for Pyramid-based Vision Transformers with Locality](https://arxiv.org/abs/2205.10063)
   - Code: [https://github.com/implus/UM-MAE](https://github.com/implus/UM-MAE)
   - Tips: : 在本文中，作者提出了统一掩蔽（Uniform Masking，UM）策略，成功地实现了基于金字塔的具有局部性的VIT的MAE预训练（简称“UM-MAE”）。
<div align=center><img src="https://mmbiz.qpic.cn/mmbiz_png/BJbRvwibeSTun9oRyfBr7b7VLYBsl2icF2VFWSTGibPTSUEcKUz1AYcBs36iaicTegtOrBcgYL315zia6L2bVBhNQztg/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" style='zoom:100%'>
</div>


4. [改进何恺明的MAE！GreenMIM：将Swin与MAE结合，训练速度大大提升！](https://mp.weixin.qq.com/s/uU4fo79U4PLZKdD7NhgL9A)       :star::star:
   - Abstract: 改进何恺明的MAE！GreenMIM：将Swin与MAE结合，训练速度大大提升！
   - Paper: [Green Hierarchical Vision Transformer for Masked Image Modeling](https://arxiv.org/abs/2205.13515)
   - Code: [https://github.com/LayneH/GreenMIM](https://github.com/LayneH/GreenMIM)
   - Tips: GreenMIM不光将Swin Transformer整合到了MAE框架上，既有与SimMIM相当的任务表现，还保证了计算效率和性能。

<div align=center><img src="https://mmbiz.qpic.cn/mmbiz_png/YicUhk5aAGtCibrQiaEfCnLJyCcyZn8ULbfNWYIpaJZQOV1LC3qHhNyRDpQmvy1xa3ANhcE1tMOrJkasYDic8QjECA/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" style='zoom:100%'>
</div>


5. [无需训练，自动扩展的视觉Transformer来了](https://mp.weixin.qq.com/s/RVKJ-SkBrmAO3drkxzVsOw)       :star::star:
   - Abstract: 无需训练，自动扩展的视觉Transformer来了
   - Paper: [Auto-scaling Vision Transformers without Training](https://arxiv.org/abs/2202.11921)
   - Tips: 得克萨斯大学奥斯汀分校、悉尼科技大学和谷歌的研究者提出了 As-ViT（Auto-scaling Vision Transformers），这是一个无需训练的 ViT 自动扩展框架，它能以高效且有原则的方式自动设计和扩展 ViT。

<div align=center><img src="https://mmbiz.qpic.cn/mmbiz_png/1MtnAxmWSwNOWgg2GyCOKhPiaZDAicic8T9WPXvHz5Ov9wicLxn0FvVrAdIRs6qu16aWrOX9ib6zlpEEbiaYTfiaNBDRQ/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" style='zoom:100%'>
</div>


6. [基于CNN的区域特定多尺度特征提取的两阶段停车位检测](https://mp.weixin.qq.com/s/lKlLQD-NuzCoKyxyS7IpKA)       :star::star:
   - Abstract: 基于CNN的区域特定多尺度特征提取的两阶段停车位检测
   - Paper: [CNN-based Two-Stage Parking Slot Detection Using Region-Specific Multi-Scale Feature Extraction](https://arxiv.org/abs/2108.06185)
   - Tips: 作者提出了一种新的高度专业化的两阶段停车位检测方法，该方法在第一阶段寻找停车位入口作为区域建议，并在第二阶段从多尺度特征地图中提取区域特定特征以精确预测停车位的位置和属性。

<div align=center><img src="https://mmbiz.qpic.cn/mmbiz_png/SdQCib1UzF3vSYibh5MesGyDjBN5hEq2b1NkpFcwjDTZFHibZJj6AYXDXZGYINegl6KFC81tBCjgicg0UOqheyCQaw/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" style='zoom:100%'>
</div>



## :paperclip:  Others

- 由于图片权限问题，[GitHub](https://github.com/xiaoxuebajie/dairly_learning)是完整版，可以点点 star
- 星标的数量是与个人相关程度，不代表文章内容的好坏
- 关注我的[个人网站](http://www.cvbds.cn/)
- 关注我的[CSDN](https://blog.csdn.net/xiaoxuebajie)博客
- 关注我的[哔哩哔哩](https://space.bilibili.com/424394389)
- 关注我的公众号CV伴读社

<div align=center><img src="https://img-blog.csdnimg.cn/202005031406335.jpg" style='zoom:80%'>
</div>